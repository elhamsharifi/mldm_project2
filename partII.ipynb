{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Model Building\n",
    "\n",
    "Here you try your hand at model building to predict appointment no shows.\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "Package 'proj2_lib' now includes code to carry out preprocessing steps from part I. Here's how to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import proj2_lib.util as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, it includes a dictionary used for configuring path and file names\n",
    "used through the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_pipeline_file': 'feature_pipeline.pkl',\n",
       " 'labels_pipeline_file': 'labels_pipeline.pkl',\n",
       " 'objstore_path': 'objects',\n",
       " 'processed_data_path': 'processed_data',\n",
       " 'raw_data_csv': 'KaggleV2-May-2016.csv',\n",
       " 'raw_data_path': 'data',\n",
       " 'test_csv': 'test_set.csv',\n",
       " 'train_csv': 'train_set.csv'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.file_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`feature_pipeline_file`: file storing the preprocessing pipeline used for preparing the feature matrix\n",
    "\n",
    "`labels_pipeline_file`: file storing the preprocessing pipeline used for\n",
    "preparing labels\n",
    "\n",
    "`objstore_path`: directory to store python objects to disk\n",
    "\n",
    "`processed_data_path`: directory containing processed data\n",
    "\n",
    "`raw_data_csv`: name of the csv download from Kaggle\n",
    "\n",
    "`raw_data_path`: directory containing raw data\n",
    "\n",
    "`test_csv`: name of csv file containing test set\n",
    "\n",
    "`train_csv`: name of csv file containing train set\n",
    "\n",
    "You can change these paths and names to suit your project directory structure if you need so. E.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_config = utils.file_config\n",
    "#config['raw_data_path'] = \"some_other_directory\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to create train test sets. Code is in file `proj2_lib/util.py` function `make_train_test_sets`. You\n",
    "can edit that function as needed to include your own part I code if you so desire. The result will be to \n",
    "create files `train_set.csv` and `test_set.csv` in your `processed_data` directory (unless you change any of the entries in the configuration directory as above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY NEED TO RUN THIS STEP ONCE (switch this to True to run it)\n",
    "RUN_MAKE_TRAIN_TEST_FILES = True\n",
    "if RUN_MAKE_TRAIN_TEST_FILES:\n",
    "    utils.make_train_test_sets(config=file_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to fit the preprocessing pipelines. This is done in file `proj2_lib/preprocess.py`. Again you can edit code as needed in that file to incorporate your part I solution as you wish. The result will be to create files `feature_pipeline.pkl` and `labels_pipeline.pkl` containing the fit preprocessing pipelines we can then use to preprocess data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import proj2_lib.preprocess as preprocess\n",
    "\n",
    "# ONLY NEED TO RUN THIS STEP ONCE\n",
    "RUN_FIT_PREPROCESSING = True\n",
    "if RUN_FIT_PREPROCESSING:\n",
    "    preprocess.fit_save_pipelines(config=file_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, once we do that, we can get a training matrix and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = preprocess.load_train_data(config=file_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90514, 105)\n",
      "(90514,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building\n",
    "\n",
    "Using `sklearn` fit:\n",
    "    - DecisionTree classifier\n",
    "    - RandomForest classifier\n",
    "    - Linear SVM classifier\n",
    "    - SVM with Radial Basis Kernel classifier\n",
    "    \n",
    "Use default parameters for now.\n",
    "Using 10-fold cross validation report both accuracy and AUC for each of the above four models.\n",
    "\n",
    "QUESTION: Should you use accuracy or AUC for this task as a performance metric?\n",
    "\n",
    "_ANSWER HERE_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Model\n",
    "### Here I am building a decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build your models here\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT_clf = DecisionTreeClassifier()\n",
    "DT_clf_fit=DT_clf.fit(train_X, train_y)\n",
    "\n",
    "n_nodes = DT_clf.tree_.node_count\n",
    "children_left = DT_clf.tree_.children_left\n",
    "children_right = DT_clf.tree_.children_right\n",
    "feature = DT_clf.tree_.feature\n",
    "threshold = DT_clf.tree_.threshold\n",
    "DT_clf_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model\n",
    "### Here I am building a random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_clf = RandomForestClassifier()\n",
    "RF_clf_fit=RF_clf.fit(train_X,train_y)\n",
    "RF_clf_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.31643899e-02   1.54275489e-02   1.41307162e-02   1.41712178e-02\n",
      "   1.46843735e-02   1.35188237e-04   0.00000000e+00   1.70640277e-01\n",
      "   4.06676865e-02   8.49516830e-03   1.04989206e-02   6.20693191e-03\n",
      "   1.02438855e-02   1.28090233e-02   7.64134572e-03   7.24926614e-03\n",
      "   2.00223006e-02   3.23069374e-01   3.61826596e-02   3.26648364e-03\n",
      "   3.22063794e-03   6.12383562e-04   1.12244360e-04   2.01911745e-05\n",
      "   1.06230440e-05   5.89537448e-03   1.22038377e-03   1.26463829e-03\n",
      "   1.66524650e-03   4.89645338e-03   3.02962307e-03   1.52521339e-03\n",
      "   5.62873310e-03   6.65332537e-03   7.01928165e-03   1.37378412e-03\n",
      "   2.90140739e-03   4.09596628e-03   4.64727072e-03   5.08045070e-03\n",
      "   1.29544365e-03   1.65142051e-03   1.86806229e-03   2.73066273e-03\n",
      "   1.10446070e-03   2.29967432e-03   2.76422802e-03   3.92518714e-03\n",
      "   1.01548037e-03   2.94202070e-03   3.66952737e-03   5.24031114e-03\n",
      "   1.00698454e-03   3.04076671e-03   4.28108019e-03   8.72856296e-05\n",
      "   6.75824715e-05   4.53158075e-03   6.55458373e-05   3.37441773e-03\n",
      "   5.31104011e-03   4.75755218e-03   8.44952409e-03   5.06952284e-03\n",
      "   4.91021130e-03   4.28938346e-03   2.68921328e-03   7.56056018e-03\n",
      "   5.30201657e-03   1.91682436e-03   2.81666309e-03   6.20161986e-04\n",
      "   1.26841798e-03   6.80176967e-04   4.83579569e-03   1.93770913e-08\n",
      "   3.15639678e-03   1.97970121e-03   3.79688799e-04   2.76228168e-03\n",
      "   4.14275410e-03   3.91866900e-03   2.95701746e-03   8.03133516e-03\n",
      "   5.82669046e-03   2.29834344e-03   2.40044384e-03   1.05594904e-03\n",
      "   1.60339184e-03   1.75332599e-03   5.81955880e-03   4.01540937e-03\n",
      "   5.87479078e-03   5.44560065e-03   4.85266634e-03   2.17898076e-03\n",
      "   7.97343412e-04   1.73418241e-03   4.02545400e-03   5.15110659e-03\n",
      "   4.94997704e-03   5.41918383e-03   7.01915927e-03   7.94382628e-04\n",
      "   2.63741912e-03]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(RF_clf.feature_importances_)\n",
    "len((RF_clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM Model\n",
    "### Here I am building a linear SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "SVM_clf = LinearSVC()\n",
    "SVM_clf_fit=SVM_clf.fit(train_X,train_y)\n",
    "SVM_clf_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.56375836e-02  -1.84660885e-02  -4.19392575e-02  -5.15276295e-02\n",
      "   -3.00777533e-02  -8.62549894e-02   0.00000000e+00   1.44237597e-02\n",
      "   -4.76703468e-01  -2.29575874e-02   1.18749987e-01   1.37007767e-01\n",
      "    7.10344759e-02  -4.04979143e-02   3.72598514e-02   9.48207261e-02\n",
      "   -8.64056566e-02  -5.97024591e-02   1.08833684e-03  -1.76417626e-01\n",
      "   -1.35153303e-01  -1.33883643e-01   7.74319340e-02   1.24119336e-01\n",
      "   -4.56272161e-01   4.28796084e-02  -7.20388795e-02   3.00010592e-02\n",
      "    4.72895891e-02   5.04051688e-02   3.70521404e-03  -5.26479596e-02\n",
      "    1.66961686e-02   4.67088366e-02   1.64575397e-02  -5.41775963e-02\n",
      "    3.45089100e-02  -2.31272047e-02   5.70372120e-03   3.74835441e-03\n",
      "   -1.67998525e-01  -7.09494354e-02  -3.37505821e-02  -9.58989276e-02\n",
      "   -2.07910446e-02  -3.30467896e-04   4.46146953e-03  -4.63316417e-02\n",
      "   -1.89386828e-03  -4.33300473e-02   1.38578349e-02   6.39902286e-02\n",
      "    7.78606761e-02   6.22534308e-02  -2.96033562e-02  -2.32816184e-01\n",
      "    1.01938614e-01   7.90695978e-02   1.08698420e+00  -5.99981946e-02\n",
      "    9.27627707e-02  -7.02804051e-02  -2.29667405e-02  -7.54208444e-02\n",
      "    7.72114999e-02  -4.63769377e-02  -2.11222563e-02   9.23466996e-03\n",
      "    1.93497803e-02  -9.84699244e-02  -6.78734358e-02  -8.97434454e-02\n",
      "   -1.24121125e-02  -4.86595814e-02   1.97283244e-02  -6.25227134e-02\n",
      "    4.78245927e-02  -1.93137824e-02  -7.04736157e-02   2.81492895e-02\n",
      "    1.69879048e-02  -2.89329530e-02  -4.66512968e-02   8.08833238e-03\n",
      "    2.42536568e-02   4.60633672e-02   4.21241847e-02   1.58738212e-02\n",
      "   -5.50878014e-02   9.65636579e-03  -4.26652155e-02  -2.93649302e-02\n",
      "    2.90768271e-03  -5.05975567e-03   1.59168248e-01  -2.18223173e-02\n",
      "   -6.65093552e-02  -1.52689394e-01   9.22860978e-03  -1.84351288e-02\n",
      "    3.54366397e-02   3.48655430e-02  -3.26727144e-02   2.71264207e-02\n",
      "   -9.09824982e-02]]\n",
      "[-0.2439033]\n"
     ]
    }
   ],
   "source": [
    "print(SVM_clf.coef_)\n",
    "print(SVM_clf.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF SVM Model\n",
    "### Here I am building a SVM with radial basis kernel  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "RBF_SVM_clf= svm.SVC(kernel=\"rbf\")\n",
    "RBF_SVM_clf_fit= RBF_SVM_clf.fit(train_X,train_y)\n",
    "RBF_SVM_clf_fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we look at mean and standard deviation of accuracy and roc-auc score for the 4 models we fit above. We use 10 fold cross validation. From the results we can see that for all the models accuracy doesn't change a lot. Roc-auc score is the one changing a lot and it seems that roc-auc score is more important here. Based on the results of this section Linear SVM and Random Forest have higher roc-auc scores and we choose these two as the better models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best') Scores: accuracy Mean: 0.74 (+/- 0.01)\n",
      "clf DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best') Scores: AUC Mean: 0.59 (+/- 0.01)\n",
      "clf RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False) Scores: accuracy Mean: 0.78 (+/- 0.01)\n",
      "clf RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False) Scores: AUC Mean: 0.70 (+/- 0.01)\n",
      "clf LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0) Scores: accuracy Mean: 0.80 (+/- 0.00)\n",
      "clf LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0) Scores: AUC Mean: 0.72 (+/- 0.01)\n",
      "clf SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) Scores: accuracy Mean: 0.80 (+/- 0.00)\n",
      "clf SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) Scores: AUC Mean: 0.61 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for clf in (DT_clf,RF_clf,SVM_clf,RBF_SVM_clf):\n",
    "    accuracy_scores = cross_val_score(clf, train_X, train_y, \n",
    "                        scoring=\"accuracy\", cv=10)\n",
    "    roc_scores = cross_val_score(clf, train_X, train_y, \n",
    "                        scoring=\"roc_auc\", cv=10)\n",
    "    print(\"clf\", clf, \"Scores:\", \"accuracy\",\"Mean: %0.2f (+/- %0.2f)\" % (accuracy_scores.mean(), accuracy_scores.std() * 2))\n",
    "    print(\"clf\", clf, \"Scores:\", \"AUC\",\"Mean: %0.2f (+/- %0.2f)\" % (roc_scores.mean(), roc_scores.std() * 2))\n",
    "    \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning\n",
    "\n",
    "Based on the above, choose two methods and fit a tuned model:\n",
    "    - use 5-fold cross validation for model selection\n",
    "    - use 10-fold cross validation for model assessment (based on appropriate performance metric)\n",
    "\n",
    "Report estimated performance for both tuned classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we use 5 fold cross validation to select the best model based on a range of parameters. The parameters for best models are shown in the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random_Forest_Best_params_AUC:  {'max_features': 18, 'n_estimators': 90}\n",
      "Best RF AUC score is 0.7241072475754243\n",
      "Linear_SVM_Best_params_AUC:  {'C': 0.01}\n",
      "Best Linear SVM AUC score is 0.7233435445332445\n"
     ]
    }
   ],
   "source": [
    "# tune your models here\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 30, 60,90,100], 'max_features': [5, 10, 18, 25, 30]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 30, 60,90,100], 'max_features': [5, 10, 18, 25, 30]}\n",
    "]\n",
    "\n",
    "RF_gs = GridSearchCV(estimator=RF_clf, param_grid=param_grid, cv= 5, scoring=\"roc_auc\")\n",
    "RF_gs.fit(train_X, train_y)\n",
    "print (\"Random_Forest_Best_params_AUC: \", RF_gs.best_params_)\n",
    "print(\"Best RF AUC score is {}\".format(RF_gs.best_score_))\n",
    "\n",
    "\n",
    "\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "param_grid = {'C': Cs}\n",
    "SVM_gs = GridSearchCV(estimator=SVM_clf, param_grid=param_grid, cv=5, scoring=\"roc_auc\" )\n",
    "\n",
    "SVM_gs.fit(train_X, train_y)\n",
    "print (\"Linear_SVM_Best_params_AUC: \", SVM_gs.best_params_) \n",
    "print(\"Best Linear SVM AUC score is {}\".format(SVM_gs.best_score_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we are using 10 fold cross validation for model assessment. We use the best estimator in each model and then find the mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=18, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=90, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False) Scores: AUC best_gs_Mean: 0.73 (+/- 0.01)\n",
      "clf LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0) Scores: AUC best_gs_Mean: 0.72 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "for clf in (RF_gs.best_estimator_ ,SVM_gs.best_estimator_  ):\n",
    "    \n",
    "    roc_scores = cross_val_score(clf, train_X, train_y, \n",
    "                        scoring=\"roc_auc\", cv=10)\n",
    "    \n",
    "    print(\"clf\", clf, \"Scores:\", \"AUC\",\"best_gs_Mean: %0.2f (+/- %0.2f)\" % (roc_scores.mean(), roc_scores.std() * 2))\n",
    "    \n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM with Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# initialize model parameters w and b\n",
    "# intializing to 0 is not a good idea\n",
    "# it should be a random vector see np.random.randn\n",
    "# YOU NEED TO IMPLEMENT THIS\n",
    "def _initialize_parameters(nfeatures):\n",
    "    w = np.full((nfeatures), np.random.randn())\n",
    "    b = np.full((1), np.random.randn())\n",
    "    return w, b\n",
    "\n",
    "# this is a vectorized version of positive_part operation\n",
    "# we can use this for hinge loss as post_part(1.0 - y*f)\n",
    "pos_part = np.vectorize(lambda u: u if u > 0. else 0.)\n",
    "\n",
    "# compute the value of the linear SVM objective function\n",
    "# given current signed distances, and parameter vector w\n",
    "def _get_objective(f, y, w, lam):\n",
    "    loss = np.sum(pos_part(1.0 - y*f))\n",
    "    penalty = lam * np.dot(w.transpose(),w)\n",
    "    return loss + penalty\n",
    "\n",
    "# compute the signed distances\n",
    "# based on current model estimates\n",
    "# w and b\n",
    "# YOU NEED TO IMPLEMENT THIS\n",
    "def _get_signed_distances(X, w, b):\n",
    "    nobs = X.shape[0]\n",
    "    f = np.full(nobs, 0.0)\n",
    "    w_T=w.copy()\n",
    "    w_len=X.shape[1]\n",
    "    w_T.resize(w_len,1) \n",
    "    #f=np.multiply(X,w_T)+b\n",
    "    f=np.mat(X)*np.mat(w_T)+b\n",
    "    #print(\"f:\",f)\n",
    "    return f\n",
    "    \n",
    "\n",
    "# compute gradients with respect to w and b\n",
    "# YOU NEEED TO IMPLEMENT THIS\n",
    "subgrad = np.vectorize(lambda u: 0. if u >= 1. else -1.)\n",
    "\n",
    "def _get_gradients(f, X, y, w, b, lam):\n",
    "    yf = y * f\n",
    "    t = subgrad(yf)\n",
    "    ty = t * y\n",
    "    \n",
    "    gw = np.sum(np.dot(X.T, ty.T))+lam*w\n",
    "    gb = np.sum(ty)\n",
    "    return gw, gb\n",
    "\n",
    "# fit an SVM using gradient descent\n",
    "# X: matrix of feature values\n",
    "# y: labels (-1 or 1)\n",
    "# n_iter: numer of iterations\n",
    "# eta: learning rate\n",
    "def fit_svm(X, y, lam, n_iter=100, eta=.4):\n",
    "    nexamples, nfeatures = X.shape\n",
    "    \n",
    "    w, b = _initialize_parameters(nfeatures)\n",
    "    \n",
    "    for k in range(n_iter):\n",
    "        f = _get_signed_distances(X, w, b)\n",
    "        \n",
    "        # print information and \n",
    "        # update the learning rate\n",
    "        if k % 10 == 0:\n",
    "            obj = _get_objective(f, y, w, lam)\n",
    "            eta = eta / 2.0\n",
    "            print(\"it: %d, obj %.2f\" % (k, obj))\n",
    "        \n",
    "        gw, gb = _get_gradients(f, X, y, w, b, lam)\n",
    "        #print(\"gw:\",gw)\n",
    "        w = w - eta * gw\n",
    "        b = b - eta * b\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it: 0, obj 165.89\n",
      "it: 10, obj 1.91\n",
      "it: 20, obj 0.23\n",
      "it: 30, obj 0.08\n",
      "it: 40, obj 0.05\n",
      "it: 50, obj 0.04\n",
      "it: 60, obj 0.03\n",
      "it: 70, obj 0.03\n",
      "it: 80, obj 0.03\n",
      "it: 90, obj 0.03\n"
     ]
    }
   ],
   "source": [
    "w,b = fit_svm(train_X, train_y, 1.0, n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
